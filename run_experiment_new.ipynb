{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logger import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training pipelines\n",
    "def train_main(model, optimizer, loader_train, loader_val, epochs=1, model_path=None, early_stop_patience = 0):\n",
    "    \"\"\"\n",
    "    Train the main branch\n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Logger object with loss and accuracy data\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    logger = Logger()\n",
    "    last_loss = float('inf')\n",
    "    for e in range(epochs):\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        total_loss = 0.0\n",
    "        count = 0\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f\"\\r[Epoch {e + 1}, Batch {t}] train_loss: {loss.item()}\", end='')\n",
    "            count += 1\n",
    "\n",
    "        # Conclude Epoch\n",
    "        train_loss = total_loss / count\n",
    "        train_acc = float(num_correct) / num_samples\n",
    "        val_loss, val_acc = evaluate_main(model, loader_val)\n",
    "        logger.log(train_loss, train_acc, val_loss, val_acc)\n",
    "        \n",
    "        with open(model_path.split('.')[0] + '.pkl', 'wb') as output_file:\n",
    "            pickle.dump(logger, output_file)\n",
    "\n",
    "        # Early Stopping\n",
    "        if logger.check_early_stop(early_stop_patience):\n",
    "            print(\"[Early Stopped]\")\n",
    "            break\n",
    "        else:\n",
    "            if last_loss > val_loss:\n",
    "                print(f\"\\r[Epoch {e}] train_acc: {train_acc}, val_acc:{val_acc}, val_loss improved from %.4f to %.4f. Saving model to {model_path}.\" % (last_loss, val_loss))\n",
    "                if model_path is not None:\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "            else:\n",
    "                print(f\"\\r[Epoch {e}] train_acc: {train_acc}, val_acc:{val_acc}, val_loss did not improve from %.4f\" % (last_loss))\n",
    "            last_loss = val_loss\n",
    "    return logger, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_both(model, optimizer, loader_train, loader_val, epochs=1, model_path=None, early_stop_patience = 0):\n",
    "    \"\"\"\n",
    "    Train the main and auxillary branch\n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Logger object with loss and accuracy data\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    logger = Logger()\n",
    "    last_loss = float('inf')\n",
    "    for e in range(epochs):\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        running_loss = 0.0\n",
    "        count = 0\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss_main = F.cross_entropy(scores[0], y[:, 0])\n",
    "            loss_auxillary = F.cross_entropy(scores[1], y[:, 1])\n",
    "            loss = loss_main + loss_auxillary\n",
    "            running_loss += loss_main.item()\n",
    "\n",
    "            _, preds = scores[0].max(1)\n",
    "            num_correct += (preds == y[:, 0]).sum()\n",
    "            num_samples += preds.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f\"\\r[Epoch {e}, Batch {t}] train_loss: {loss.item()}\", end='')\n",
    "            count += 1\n",
    "\n",
    "        # Conclude Epoch\n",
    "        train_loss = running_loss / count\n",
    "        train_acc = float(num_correct) / num_samples\n",
    "        val_loss, val_acc = evaluate_both(model, loader_val)\n",
    "        logger.log(train_loss, train_acc, val_loss, val_acc)\n",
    "\n",
    "        with open(model_path.split('.')[0] + '.pkl', 'wb') as output_file:\n",
    "            pickle.dump(logger, output_file)\n",
    "            \n",
    "        # Early Stopping\n",
    "        if logger.check_early_stop(early_stop_patience):\n",
    "            print(\"[Early Stopped]\")\n",
    "            break\n",
    "        else:\n",
    "            if last_loss > val_loss:\n",
    "                print(f\"\\r[Epoch {e}] train_acc: {train_acc}, val_acc:{val_acc}, val_loss improved from %.4f to %.4f. Saving model to {model_path}.\" % (last_loss, val_loss))\n",
    "                if model_path is not None:\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "            else:\n",
    "                print(f\"\\r[Epoch {e}] train_acc: {train_acc}, val_acc:{val_acc}, val_loss did not improve from %.4f\" % (last_loss))\n",
    "            last_loss = val_loss\n",
    "    return logger, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_main(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluate main branch accuracy\n",
    "    Outputs: loss and accuracy\n",
    "    \"\"\"\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    ave_loss = 0.0\n",
    "    count = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            # print(scores.shape)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "            ave_loss += loss.item()\n",
    "            count += 1\n",
    "        acc = float(num_correct) / num_samples\n",
    "        return ave_loss / count, acc\n",
    "\n",
    "def evaluate_both(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluate main branch accuracy in model with two predictions\n",
    "    Outputs: loss and accuracy\n",
    "    \"\"\"\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    ave_loss = 0.0\n",
    "    count = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            loss_main = F.cross_entropy(scores[0], y[:, 0])\n",
    "            # print(scores.shape)\n",
    "            _, preds = scores[0].max(1)\n",
    "            num_correct += (preds == y[:, 0]).sum()\n",
    "            # print(f\"num_correct: {num_correct}\")\n",
    "            num_samples += preds.size(0)\n",
    "            # print(f\"num_samples: {num_samples}\")\n",
    "            ave_loss += loss_main.item()\n",
    "            count += 1\n",
    "        acc = float(num_correct) / num_samples\n",
    "        return ave_loss / count, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_non_rotate(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluate main branch accuracy in model with two predictions\n",
    "    Outputs: loss and accuracy\n",
    "    \"\"\"\n",
    "    from random import randrange\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    ave_loss = 0.0\n",
    "    count = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            loss_main = F.cross_entropy(scores[0], y)\n",
    "            # print(scores.shape)\n",
    "            _, preds = scores[0].max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            #print(f\"num_correct: {num_correct}\")\n",
    "            num_samples += preds.size(0)\n",
    "            #print(f\"num_samples: {num_samples}\")\n",
    "            ave_loss += loss_main.item()\n",
    "            count += 1\n",
    "        acc = float(num_correct) / num_samples\n",
    "        return ave_loss / count, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttt(model, loader, loader_spinned, optimizer):\n",
    "    \"\"\"\n",
    "    TTT with image spinning task\n",
    "    Outputs: loss and accuracy\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    for x, y in loader_spinned:\n",
    "        x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "        scores = model(x)\n",
    "        loss_auxillary = F.cross_entropy(scores[1], y[:, 1])\n",
    "        optimizer.zero_grad()\n",
    "        loss_auxillary.backward()\n",
    "        optimizer.step()\n",
    "    return evaluate_non_rotate(model, loader)"
   ]
  },
  {
   "source": [
    "# Experiment 1: Baseline ResNet18\n",
    "## Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: Train a baseline ResNet18: no branch\n",
    "lr = 1e-3\n",
    "wd = 1e-4\n",
    "batch_size = 1024\n",
    "train_set = TensorDataset(torch.load('train_x.pt'), torch.load('train_y.pt'))\n",
    "val_set = TensorDataset(torch.load('val_x.pt'), torch.load('val_y.pt'))\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "from models import ResNetMainBranch\n",
    "model_base_1 = ResNetMainBranch()\n",
    "optimizer = optim.Adam(model_base_1.parameters(), lr=lr, weight_decay=wd)\n",
    "train_main(model_base_1, optimizer, train_loader, val_loader, epochs=30, model_path='model_base_1.pth', early_stop_patience=5)"
   ]
  },
  {
   "source": [
    "## Evaluate on Uncorrupted Test Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "batch_size = 1024\n",
    "test_set = TensorDataset(torch.load('test_x.pt'), torch.load('test_y.pt'))\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "from models import ResNetMainBranch\n",
    "model_path = 'model_base_1.pth'\n",
    "model_base_1 = ResNetMainBranch()\n",
    "params = torch.load(model_path)\n",
    "model_base_1.load_state_dict(params)\n",
    "model_base_1 = model_base_1.to(device=device)\n",
    "print('Uncorrupted test set: ', evaluate_main(model_base_1, test_loader))"
   ]
  },
  {
   "source": [
    "## Evaluate on Corrupted Test Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "test_gauss_set = TensorDataset(torch.load('test_x_gauss_noise.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_gauss_loader = DataLoader(test_gauss_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_defocus_set = TensorDataset(torch.load('test_x_defocus_blur.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_defocus_loader = DataLoader(test_defocus_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_elastic_set = TensorDataset(torch.load('test_x_elastic_transform.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_elastic_loader = DataLoader(test_elastic_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_motion_set = TensorDataset(torch.load('test_x_motion_blur.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_motion_loader = DataLoader(test_motion_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_zoom_set = TensorDataset(torch.load('test_x_zoom_blur.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_zoom_loader = DataLoader(test_zoom_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "from models import ResNetMainBranch\n",
    "model_path = 'model_base_1.pth'\n",
    "model_base_1 = ResNetMainBranch()\n",
    "params = torch.load(model_path)\n",
    "model_base_1.load_state_dict(params)\n",
    "model_base_1 = model_base_1.to(device=device)\n",
    "\n",
    "print(\"Gaussian noise: \", evaluate_main(model_base_1, test_gauss_loader))\n",
    "print(\"Defocus blur: \", evaluate_main(model_base_1, test_defocus_loader))\n",
    "print(\"Elastic transform: \", evaluate_main(model_base_1, test_elastic_loader))\n",
    "print(\"Motion blur: \", evaluate_main(model_base_1, test_motion_loader))\n",
    "print(\"Zoom blur: \", evaluate_main(model_base_1, test_zoom_loader))\n"
   ]
  },
  {
   "source": [
    "# Experiment 2: ResNet18 with Auxillary Branch (No Online Training)\n",
    "## Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "batch_size = 1024\n",
    "train_mean = [86.69585, 86.342995, 85.84817]\n",
    "train_std = [74.59906, 74.196365, 73.890495]\n",
    "\n",
    "train_rotate_set = TensorDataset(torch.load('train_x_rotate.pt'), torch.load('train_y_rotate.pt'))\n",
    "val_rotate_set = TensorDataset(torch.load('val_x_rotate.pt'), torch.load('val_y_rotate.pt'))\n",
    "\n",
    "train_rotate_loader = DataLoader(train_rotate_set, batch_size=batch_size, shuffle=True)\n",
    "val_rotate_loader = DataLoader(val_rotate_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "from models import ResNetTwoBranch\n",
    "exp_2_model_1 = ResNetTwoBranch()\n",
    "optimizer = optim.Adam(exp_2_model_1.parameters(), lr=lr, weight_decay=wd)\n",
    "train_both(exp_2_model_1, optimizer, train_rotate_loader, val_rotate_loader, epochs=50, model_path='exp_2_model_1.pth', early_stop_patience=5)"
   ]
  },
  {
   "source": [
    "## Evaluate on Uncorrupted Test Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "test_set = TensorDataset(torch.load('test_x.pt'), torch.load('test_y.pt'))\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "from models import ResNetTwoBranch\n",
    "model_path = 'exp_2_model_1.pth'\n",
    "exp_2_model_1 = ResNetTwoBranch()\n",
    "params = torch.load(model_path)\n",
    "exp_2_model_1.load_state_dict(params)\n",
    "exp_2_model_1 = exp_2_model_1.to(device=device)\n",
    "print('Uncorrupted test set: ', evaluate_non_rotate(exp_2_model_1, test_loader))"
   ]
  },
  {
   "source": [
    "## Evaluate on Corrupted Test Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "test_gauss_set = TensorDataset(torch.load('test_x_gauss_noise.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_gauss_loader = DataLoader(test_gauss_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_defocus_set = TensorDataset(torch.load('test_x_defocus_blur.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_defocus_loader = DataLoader(test_defocus_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_elastic_set = TensorDataset(torch.load('test_x_elastic_transform.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_elastic_loader = DataLoader(test_elastic_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_motion_set = TensorDataset(torch.load('test_x_motion_blur.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_motion_loader = DataLoader(test_motion_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_zoom_set = TensorDataset(torch.load('test_x_zoom_blur.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_zoom_loader = DataLoader(test_zoom_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "from models import ResNetTwoBranch\n",
    "model_path = 'exp_2_model_1.pth'\n",
    "exp_2_model_1 = ResNetTwoBranch()\n",
    "params = torch.load(model_path)\n",
    "exp_2_model_1.load_state_dict(params)\n",
    "exp_2_model_1 = exp_2_model_1.to(device=device)\n",
    "\n",
    "print(\"Gaussian noise: \", evaluate_non_rotate(exp_2_model_1, test_gauss_loader))\n",
    "print(\"Defocus blur: \", evaluate_non_rotate(exp_2_model_1, test_defocus_loader))\n",
    "print(\"Elastic transform: \", evaluate_non_rotate(exp_2_model_1, test_elastic_loader))\n",
    "print(\"Motion blur: \", evaluate_non_rotate(exp_2_model_1, test_motion_loader))\n",
    "print(\"Zoom blur: \", evaluate_non_rotate(exp_2_model_1, test_zoom_loader))"
   ]
  },
  {
   "source": [
    "# Experiment 3: ResNet18 with Auxillary Branch (TTT)\n",
    "## Prepare Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_part3(model_path):\n",
    "    lr = 1e-5\n",
    "    wd = 1e-8\n",
    "    from models import ResNetTwoBranch\n",
    "    exp_3_model_1 = ResNetTwoBranch()\n",
    "    params = torch.load(model_path)\n",
    "    exp_3_model_1.load_state_dict(params)\n",
    "    optimizer = optim.Adam(exp_3_model_1.parameters(), lr=lr, weight_decay=wd)\n",
    "    return exp_3_model_1, optimizer"
   ]
  },
  {
   "source": [
    "## TTT on Uncorrupted Test Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "test_set = TensorDataset(torch.load('test_x.pt'), torch.load('test_y.pt'))\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "exp_3_model_1, optimizer = initialize_model('exp_2_model_1.pth')\n",
    "print('Uncorrupted test set: ', ttt(exp_3_model_1, test_loader, test_rotate_loader, optimizer))"
   ]
  },
  {
   "source": [
    "## TTT on Corrupted Test Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "test_gauss_set = TensorDataset(torch.load('test_x_gauss_noise.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_gauss_loader = DataLoader(test_gauss_set, batch_size=batch_size, shuffle=True)\n",
    "test_gauss_rotate_set = TensorDataset(torch.load('test_x_rotate_gauss_noise.pt'), torch.load('test_y_rotate_corrupted.pt'))\n",
    "test_gauss_rotate_loader = DataLoader(test_gauss_rotate_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_defocus_set = TensorDataset(torch.load('test_x_defocus_blur.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_defocus_loader = DataLoader(test_defocus_set, batch_size=batch_size, shuffle=True)\n",
    "test_defocus_rotate_set = TensorDataset(torch.load('test_x_rotate_defocus_blur.pt'), torch.load('test_y_rotate_corrupted.pt'))\n",
    "test_defocus_rotate_loader = DataLoader(test_defocus_rotate_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_elastic_set = TensorDataset(torch.load('test_x_elastic_transform.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_elastic_loader = DataLoader(test_elastic_set, batch_size=batch_size, shuffle=True)\n",
    "test_elastic_rotate_set = TensorDataset(torch.load('test_x_rotate_elastic_transform.pt'), torch.load('test_y_rotate_corrupted.pt'))\n",
    "test_elastic_rotate_loader = DataLoader(test_elastic_rotate_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_motion_set = TensorDataset(torch.load('test_x_motion_blur.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_motion_loader = DataLoader(test_motion_set, batch_size=batch_size, shuffle=True)\n",
    "test_motion_rotate_set = TensorDataset(torch.load('test_x_rotate_motion_blur.pt'), torch.load('test_y_rotate_corrupted.pt'))\n",
    "test_motion_rotate_loader = DataLoader(test_motion_rotate_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_zoom_set = TensorDataset(torch.load('test_x_zoom_blur.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_zoom_loader = DataLoader(test_zoom_set, batch_size=batch_size, shuffle=True)\n",
    "test_zoom_rotate_set = TensorDataset(torch.load('test_x_rotate_zoom_blur.pt'), torch.load('test_y_rotate_corrupted.pt'))\n",
    "test_zoom_rotate_loader = DataLoader(test_zoom_rotate_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loaders = [(test_gauss_loader, test_gauss_rotate_loader), \n",
    "                (test_defocus_loader, test_defocus_rotate_loader),\n",
    "                (test_elastic_loader, test_elastic_rotate_loader),\n",
    "                (test_motion_loader, test_motion_rotate_loader),\n",
    "                (test_zoom_loader, test_zoom_rotate_loader)]\n",
    "test_names = [\"Gaussian noise\", \"Defocus blur\", \"Elastic transform\", 'Motion blur', 'Zoom blur']\n",
    "\n",
    "for i in len(test_loaders):\n",
    "    exp_3_model_1, optimizer = initialize_model_part3('exp_2_model_1.pth')\n",
    "    print(test_names[i], ': ', ttt(exp_3_model_1, test_loaders[i][0], test_loaders[i][1], optimizer))"
   ]
  },
  {
   "source": [
    "# Experiment 4: ResNet18 with Auxillary Branch (TTT Online)\n",
    "## Prepare Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_part4(model_path):\n",
    "    lr = 1e-5\n",
    "    wd = 1e-8\n",
    "    from models import ResNetTwoBranch\n",
    "    exp_4_model_1 = ResNetTwoBranch()\n",
    "    params = torch.load(model_path)\n",
    "    exp_4_model_1.load_state_dict(params)\n",
    "    optimizer = optim.Adam(exp_4_model_1.parameters(), lr=lr, weight_decay=wd)\n",
    "    return exp_4_model_1, optimizer"
   ]
  },
  {
   "source": [
    "## TTT on Uncorrupted Test Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "test_set = TensorDataset(torch.load('test_x.pt'), torch.load('test_y.pt'))\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "exp_3_model_1, optimizer = initialize_model('exp_2_model_1.pth')\n",
    "print('Uncorrupted test set: ', ttt(exp_3_model_1, test_loader, test_rotate_loader, optimizer))"
   ]
  },
  {
   "source": [
    "## TTT on Corrupted Test Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "test_gauss_set = TensorDataset(torch.load('test_x_gauss_noise.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_gauss_loader = DataLoader(test_gauss_set, batch_size=batch_size, shuffle=False)\n",
    "test_gauss_rotate_set = TensorDataset(torch.load('test_x_rotate_gauss_noise.pt'), torch.load('test_y_rotate_corrupted.pt'))\n",
    "test_gauss_rotate_loader = DataLoader(test_gauss_rotate_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_defocus_set = TensorDataset(torch.load('test_x_defocus_blur.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_defocus_loader = DataLoader(test_defocus_set, batch_size=batch_size, shuffle=False)\n",
    "test_defocus_rotate_set = TensorDataset(torch.load('test_x_rotate_defocus_blur.pt'), torch.load('test_y_rotate_corrupted.pt'))\n",
    "test_defocus_rotate_loader = DataLoader(test_defocus_rotate_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_elastic_set = TensorDataset(torch.load('test_x_elastic_transform.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_elastic_loader = DataLoader(test_elastic_set, batch_size=batch_size, shuffle=False)\n",
    "test_elastic_rotate_set = TensorDataset(torch.load('test_x_rotate_elastic_transform.pt'), torch.load('test_y_rotate_corrupted.pt'))\n",
    "test_elastic_rotate_loader = DataLoader(test_elastic_rotate_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_motion_set = TensorDataset(torch.load('test_x_motion_blur.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_motion_loader = DataLoader(test_motion_set, batch_size=batch_size, shuffle=False)\n",
    "test_motion_rotate_set = TensorDataset(torch.load('test_x_rotate_motion_blur.pt'), torch.load('test_y_rotate_corrupted.pt'))\n",
    "test_motion_rotate_loader = DataLoader(test_motion_rotate_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_zoom_set = TensorDataset(torch.load('test_x_zoom_blur.pt'), torch.load('test_y_corrupted.pt'))\n",
    "test_zoom_loader = DataLoader(test_zoom_set, batch_size=batch_size, shuffle=False)\n",
    "test_zoom_rotate_set = TensorDataset(torch.load('test_x_rotate_zoom_blur.pt'), torch.load('test_y_rotate_corrupted.pt'))\n",
    "test_zoom_rotate_loader = DataLoader(test_zoom_rotate_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_loaders = [(test_gauss_loader, test_gauss_rotate_loader), \n",
    "                (test_defocus_loader, test_defocus_rotate_loader),\n",
    "                (test_elastic_loader, test_elastic_rotate_loader),\n",
    "                (test_motion_loader, test_motion_rotate_loader),\n",
    "                (test_zoom_loader, test_zoom_rotate_loader)]\n",
    "test_names = [\"Gaussian noise\", \"Defocus blur\", \"Elastic transform\", 'Motion blur', 'Zoom blur']\n",
    "\n",
    "for i in len(test_loaders):\n",
    "    exp_4_model_1, optimizer = initialize_model_part4('exp_2_model_1.pth')\n",
    "    print(test_names[i], ': ', ttt(exp_4_model_1, test_loaders[i][0], test_loaders[i][1], optimizer))"
   ]
  }
 ]
}