{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "## Description\n",
    "\n",
    "## Pre-processing\n",
    "\n",
    "### Resizing\n",
    "\n",
    "### Random cropping\n",
    "\n",
    "### Corrupting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logger import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "batch_size = 128\n",
    "train_mean = [107.59252, 103.2752, 106.84143]\n",
    "train_std = [63.439133, 59.521027, 63.240288]\n",
    "# Preprocessing\n",
    "transform = T.Compose([\n",
    "                T.Normalize(train_mean, train_std)\n",
    "            ])\n",
    "\n",
    "#train_set = TensorDataset(torch.load('train_x.pt'), torch.load('train_y.pt'))\n",
    "#val_set = TensorDataset(torch.load('val_x.pt'), torch.load('val_y.pt'))\n",
    "#test_set = TensorDataset(torch.load('test_x.pt'), torch.load('test_y.pt'))\n",
    "\n",
    "train_rotate_set = TensorDataset(torch.load('train_x_rotate.pt'), torch.load('train_y_rotate.pt'))\n",
    "val_rotate_set = TensorDataset(torch.load('val_x_rotate.pt'), torch.load('val_y_rotate.pt'))\n",
    "test_rotate_set = TensorDataset(torch.load('test_x_rotate.pt'), torch.load('test_y_rotate.pt'))\n",
    "\n",
    "#train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "#val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "#test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_rotate_loader = DataLoader(train_rotate_set, batch_size=batch_size, shuffle=True)\n",
    "val_rotate_loader = DataLoader(val_rotate_set, batch_size=batch_size, shuffle=True)\n",
    "test_rotate_loader = DataLoader(test_rotate_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Procedures\n",
    "\n",
    "## Regular Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training pipelines\n",
    "def train_main(model, optimizer, loader_train, loader_val, epochs=1, model_path=None, early_stop_patience = 0):\n",
    "    \"\"\"\n",
    "    Train the main branch\n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Logger object with loss and accuracy data\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    logger = Logger()\n",
    "    last_loss = float('inf')\n",
    "    for e in range(epochs):\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        total_loss = 0.0\n",
    "        count = 0\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f\"\\r[Epoch {e}, Batch {t}] train_loss: {loss.item()}\", end='')\n",
    "            count += 1\n",
    "\n",
    "        # Conclude Epoch\n",
    "        train_loss = total_loss / count\n",
    "        train_acc = float(num_correct) / num_samples\n",
    "        val_loss, val_acc = evaluate_main(model, loader_val)\n",
    "        logger.log(train_loss, train_acc, val_loss, val_acc)\n",
    "        \n",
    "        with open(model_path.split('.')[0] + '.pkl', 'wb') as output_file:\n",
    "            pickle.dump(logger, output_file)\n",
    "\n",
    "        # Early Stopping\n",
    "        if logger.check_early_stop(early_stop_patience):\n",
    "            print(\"[Early Stopped]\")\n",
    "            break\n",
    "        else:\n",
    "            if last_loss > val_loss:\n",
    "                print(f\"\\r[Epoch {e}] train_acc: {train_acc}, val_acc:{val_acc}, val_loss improved from %.4f to %.4f. Saving model to {model_path}.\" % (last_loss, val_loss))\n",
    "                if model_path is not None:\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "            else:\n",
    "                print(f\"\\r[Epoch {e}] train_acc: {train_acc}, val_acc:{val_acc}, val_loss did not improve from %.4f\" % (last_loss))\n",
    "            last_loss = val_loss\n",
    "    return logger\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_both(model, optimizer, loader_train, loader_val, epochs=1, model_path=None, early_stop_patience = 0):\n",
    "    \"\"\"\n",
    "    Train the main and auxillary branch\n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Logger object with loss and accuracy data\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    logger = Logger()\n",
    "    last_loss = float('inf')\n",
    "    for e in range(epochs):\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        running_loss = 0.0\n",
    "        count = 0\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss_main = F.cross_entropy(scores[0], y[:, 0])\n",
    "            loss_auxillary = F.cross_entropy(scores[1], y[:, 1])\n",
    "            loss = loss_main + loss_auxillary\n",
    "            running_loss += loss_main.item()\n",
    "\n",
    "            _, preds = scores[0].max(1)\n",
    "            num_correct += (preds == y[:, 0]).sum()\n",
    "            num_samples += preds.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f\"\\r[Epoch {e}, Batch {t}] train_loss: {loss.item()}\", end='')\n",
    "            count += 1\n",
    "\n",
    "        # Conclude Epoch\n",
    "        train_loss = running_loss / count\n",
    "        train_acc = float(num_correct) / num_samples\n",
    "        val_loss, val_acc = evaluate_both(model, loader_val)\n",
    "        logger.log(train_loss, train_acc, val_loss, val_acc)\n",
    "\n",
    "        with open(model_path.split('.')[0] + '.pkl', 'wb') as output_file:\n",
    "            pickle.dump(logger, output_file)\n",
    "            \n",
    "        # Early Stopping\n",
    "        if logger.check_early_stop(early_stop_patience):\n",
    "            print(\"[Early Stopped]\")\n",
    "            break\n",
    "        else:\n",
    "            if last_loss > val_loss:\n",
    "                print(f\"\\r[Epoch {e}] train_acc: {train_acc}, val_acc:{val_acc}, val_loss improved from %.4f to %.4f. Saving model to {model_path}.\" % (last_loss, val_loss))\n",
    "                if model_path is not None:\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "            else:\n",
    "                print(f\"\\r[Epoch {e}] train_acc: {train_acc}, val_acc:{val_acc}, val_loss did not improve from %.4f\" % (last_loss))\n",
    "            last_loss = val_loss\n",
    "    return logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_main(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluate main branch accuracy\n",
    "    Outputs: loss and accuracy\n",
    "    \"\"\"\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    ave_loss = 0.0\n",
    "    count = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            # print(scores.shape)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "            ave_loss += loss.item()\n",
    "            count += 1\n",
    "        acc = float(num_correct) / num_samples\n",
    "        return ave_loss / count, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_both(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluate main branch accuracy in model with two predictions\n",
    "    Outputs: loss and accuracy\n",
    "    \"\"\"\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    ave_loss = 0.0\n",
    "    count = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            loss_main = F.cross_entropy(scores[0], y[:, 0])\n",
    "            # print(scores.shape)\n",
    "            _, preds = scores[0].max(1)\n",
    "            num_correct += (preds == y[:, 0]).sum()\n",
    "            print(f\"num_correct: {num_correct}\")\n",
    "            num_samples += preds.size(0)\n",
    "            print(f\"num_samples: {num_samples}\")\n",
    "            ave_loss += loss_main.item()\n",
    "            count += 1\n",
    "        acc = float(num_correct) / num_samples\n",
    "        return ave_loss / count, acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttt_online(model, loader, loader_spinned, optimizer):\n",
    "    \"\"\"\n",
    "    Online TTT with image spinning task\n",
    "    Outputs: loss and accuracy\n",
    "    \"\"\"\n",
    "    for x, y in loader_spinned:\n",
    "        x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "        scores = model(x)\n",
    "        loss_auxillary = F.cross_entropy(scores[1], y[:, 1])\n",
    "        optimizer.zero_grad()\n",
    "        loss_auxillary.backward()\n",
    "        optimizer.step()\n",
    "    return evaluate_main(model, loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Baseline ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: Train a baseline ResNet18: no branch\n",
    "lr = 1e-3\n",
    "wd = 1e-4\n",
    "from models import BaselineResNet\n",
    "model_base_1 = BaselineResNet(58)\n",
    "optimizer = optim.Adam(model_base_1.parameters(), lr=lr, weight_decay=wd)\n",
    "train_main(model_base_1, optimizer, train_loader, val_loader, epochs=25, model_path='model_base_1.pth', early_stop_patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "### Uncorrupted Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BaselineResNet\n",
    "model_path = 'model_base_4.pth'\n",
    "model_base_4 = BaselineResNet(58)\n",
    "params = torch.load(model_path)\n",
    "model_base_4.load_state_dict(params)\n",
    "model_base_4 = model_base_4.to(device=device)\n",
    "evaluate_main(model_base_4, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrupted Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: ResNet18 with Auxillary Branch (No Online Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: Train a ResNet18 with auxillary branch\n",
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "from models import ResNetTwoBranch\n",
    "model = ResNetTwoBranch()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "train_both(model, optimizer, train_rotate_loader, train_rotate_loader, epochs=50, model_path='exp_2_model.pth', early_stop_patience=5)"
   ]
  },
  {
   "source": [
    "## Evaluate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ResNetTwoBranch\n",
    "model_path = 'exp_2_model.pth'\n",
    "model = ResNetTwoBranch()\n",
    "params = torch.load(model_path)\n",
    "model.load_state_dict(params)\n",
    "model = model.to(device=device)\n",
    "evaluate_both(model, test_rotate_loader)"
   ]
  },
  {
   "source": [
    "# Experiment 3: ResNet18 with Auxillary Branch (Online-Trained)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3: Do online training on the auxillary branch, with pre-trained shared and main branch weights from experiment 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}